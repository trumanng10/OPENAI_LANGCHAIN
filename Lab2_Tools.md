# ‚öôÔ∏è **Lab 2 ‚Äî Tools for OpenAI (Function Calling / Tool Invocation)**

## üéØ **Lab Objectives**

By the end of this lab, participants will be able to:

1. Understand the concept of **Function Calling / Tool Calling** and its role in Agentic AI systems.
2. Define and register **custom tools (functions)** that allow OpenAI models to interact with external logic or APIs.
3. Invoke a tool dynamically based on model reasoning (e.g., ‚Äúget horoscope‚Äù function).
4. Capture and process **function_call outputs** before feeding results back to the model.
5. Understand how multi-turn **input lists (chat context)** manage conversation state and data flow.

---

## üß© **Scenario Overview**

Modern LLMs can now **call tools** to extend their abilities ‚Äî for example, retrieving live data or triggering business logic.
You‚Äôll create a working demo where GPT-5 uses a custom Python function (`get_horoscope`) to return a user‚Äôs horoscope automatically, using OpenAI‚Äôs **function calling interface**.

---

## üîß **Concept Primer**

> **Function Calling = Tool Access for LLMs**
> It allows the model to identify when an external function is required, generate structured arguments (JSON), and receive real-time data to complete a response.

Typical tool examples:

* `get_weather(location)` ‚Üí returns today‚Äôs forecast
* `get_account_balance(user_id)` ‚Üí fetches account details
* `issue_refund(order_id)` ‚Üí performs refund operation

**References:**

* [OpenAI Function Calling Guide](https://platform.openai.com/docs/guides/function-calling)
* [LangChain OpenAI Integration Docs](https://python.langchain.com/docs/integrations/chat/openai/)

---

## üß† **Step-by-Step Lab Guide**

### **Section 0 ‚Äî Set Up the Environment**

Before starting, ensure you have:

* Python 3.10 or Google Colab
* The `openai` library (‚â• 1.40.0)
* A valid OpenAI API key stored in `.env`

```python
!pip install -U openai>=1.40.0 python-dotenv
```

---

### **Section 1 ‚Äî Import Modules and Initialize the Client**

```python
from openai import OpenAI
import json

client = OpenAI()
```

‚úÖ This creates a connection object for sending requests to OpenAI models.

---

### **Section 2 ‚Äî Define the Tool (Function)**

Here we tell the model what tools it can call.

```python
tools = [
    {
        "type": "function",
        "name": "get_horoscope",
        "description": "Get today's horoscope for an astrological sign.",
        "parameters": {
            "type": "object",
            "properties": {
                "sign": {
                    "type": "string",
                    "description": "An astrological sign like Taurus or Aquarius",
                },
            },
            "required": ["sign"],
        },
    },
]

def get_horoscope(sign):
    return f"{sign}: Next Tuesday you will befriend a baby otter."
```

üîπ The `tools` list defines a callable function schema the model can understand.
üîπ The `get_horoscope` Python function performs the actual logic.

---

### **Section 3 ‚Äî Initialize Conversation Input**

We store all messages (user and model) in an array for multi-turn context.

```python
input_list = [
    {"role": "user", "content": "What is my horoscope? I am an Aquarius."}
]
```

---

### **Section 4 ‚Äî Invoke the Model with Tool Access**

Now we give GPT-5 access to the tool and observe its response.

```python
response = client.responses.create(
    model="gpt-5",
    tools=tools,
    input=input_list,
)

# Append the model's output to conversation
input_list += response.output
```

‚úÖ Expected: The model will decide to call `get_horoscope` and produce a `function_call` message.

---

### **Section 5 ‚Äî Process Function Calls**

If the model requested `get_horoscope`, execute the function and return its output as JSON.

```python
for item in response.output:
    if item.type == "function_call":
        if item.name == "get_horoscope":
            horoscope = get_horoscope(json.loads(item.arguments)["sign"])
            input_list.append({
                "type": "function_call_output",
                "call_id": item.call_id,
                "output": json.dumps({"horoscope": horoscope})
            })
```

---

### **Section 6 ‚Äî Generate the Final Model Response**

Now that the function output exists, send it back to the model to get a final human-readable answer.

```python
print("Final input:")
print(input_list)

response = client.responses.create(
    model="gpt-5",
    instructions="Respond only with a horoscope generated by a tool.",
    tools=tools,
    input=input_list,
)

print("Final output:")
print(response.model_dump_json(indent=2))
print("\n" + response.output_text)
```

‚úÖ **Expected Output:**
A horoscope generated from the tool, for example:

```
Aquarius: Next Tuesday you will befriend a baby otter.
```

---

### **Section 7 ‚Äî (Discussion & Learning Points)**

1. The model didn‚Äôt ‚Äúguess‚Äù the horoscope ‚Äî it **decided** to call `get_horoscope()` via structured JSON.
2. You handled the function call, then fed the output back into the conversation.
3. This architecture mirrors **Agentic AI patterns** where the LLM delegates tasks to tools or APIs.
4. You can extend this framework to connect real-world data sources ‚Äî e.g., weather APIs, databases, payment systems.

---

### **Section 8 ‚Äî Deliverables**

Students must submit:

1. Screenshot showing successful tool call (`function_call` object visible).
2. Printed final output (horoscope text).
3. 2-line explanation of how function calling differs from simple prompting.

---

### **Section 9 ‚Äî Instructor Checklist**

| ‚úÖ Checkpoint                         | Expected Outcome                            |
| ------------------------------------ | ------------------------------------------- |
| `openai` package ‚â• 1.40.0            | Confirmed                                   |
| Tool list defined correctly          | `name`, `description`, `parameters` present |
| Model invokes function call          | Output includes `function_call`             |
| Function logic executes successfully | Returns a valid string                      |
| Model responds with tool output      | Horoscope displayed in final output         |

---

### **Section 10 ‚Äî Optional Extensions**

* Add more tools (e.g., `get_weather(city)`, `get_lucky_number()`).
* Use `langchain.agents` to automate tool invocation within an Agent loop.
* Chain multiple function calls (e.g., `get_date` ‚Üí `get_weather` ‚Üí `recommend_outfit`).
* Log tool calls for observability and debugging.
